{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_emotion(row):\n",
    "    if row['Arousal'] > 5 and row['Valence'] > 5:\n",
    "        return 'HighArousal_HighValence'\n",
    "    elif row['Arousal'] > 5 and row['Valence'] <= 5:\n",
    "        return 'HighArousal_LowValence'\n",
    "    elif row['Arousal'] <= 5 and row['Valence'] > 5:\n",
    "        return 'LowArousal_HighValence'\n",
    "    else:\n",
    "        return 'LowArousal_LowValence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data_preprocessed_python/s01.dat\n",
      "Processing file: data_preprocessed_python/s02.dat\n",
      "Processing file: data_preprocessed_python/s03.dat\n",
      "Processing file: data_preprocessed_python/s04.dat\n",
      "Processing file: data_preprocessed_python/s05.dat\n",
      "Processing file: data_preprocessed_python/s06.dat\n",
      "Processing file: data_preprocessed_python/s07.dat\n",
      "Processing file: data_preprocessed_python/s08.dat\n",
      "Processing file: data_preprocessed_python/s09.dat\n",
      "Processing file: data_preprocessed_python/s10.dat\n",
      "Processing file: data_preprocessed_python/s11.dat\n",
      "Processing file: data_preprocessed_python/s12.dat\n",
      "Processing file: data_preprocessed_python/s13.dat\n",
      "Processing file: data_preprocessed_python/s14.dat\n",
      "Processing file: data_preprocessed_python/s15.dat\n",
      "Processing file: data_preprocessed_python/s16.dat\n",
      "Processing file: data_preprocessed_python/s17.dat\n",
      "Processing file: data_preprocessed_python/s18.dat\n",
      "Processing file: data_preprocessed_python/s19.dat\n",
      "Processing file: data_preprocessed_python/s20.dat\n",
      "Processing file: data_preprocessed_python/s21.dat\n",
      "Processing file: data_preprocessed_python/s22.dat\n",
      "Processing file: data_preprocessed_python/s23.dat\n",
      "Processing file: data_preprocessed_python/s24.dat\n",
      "Processing file: data_preprocessed_python/s25.dat\n",
      "Processing file: data_preprocessed_python/s26.dat\n",
      "Processing file: data_preprocessed_python/s27.dat\n",
      "Processing file: data_preprocessed_python/s28.dat\n",
      "Processing file: data_preprocessed_python/s29.dat\n",
      "Processing file: data_preprocessed_python/s30.dat\n",
      "Processing file: data_preprocessed_python/s31.dat\n",
      "Processing file: data_preprocessed_python/s32.dat\n",
      "Error Log:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "    HRV_MeanNN   HRV_SDNN  HRV_RMSSD   HRV_SDSD  HRV_CVNN  HRV_CVSD  \\\n",
      "0   923.973881  60.447814  78.978529  79.557900  0.065422  0.085477   \n",
      "1  1015.368852  50.650216  53.559802  54.009237  0.049884  0.052749   \n",
      "2   910.615809  72.630760  48.489380  48.851811  0.079760  0.053249   \n",
      "3  1013.191598  53.589061  76.280305  76.919997  0.052891  0.075287   \n",
      "4   958.618164  71.503630  95.333233  96.089137  0.074590  0.099449   \n",
      "\n",
      "   HRV_MedianNN  HRV_MadNN  HRV_MCVNN   HRV_IQRNN  ...  HRV_pNN50  HRV_pNN20  \\\n",
      "0     921.87500  46.331250   0.050258   66.406250  ...  37.313433  70.149254   \n",
      "1    1015.62500  46.331250   0.045618   62.500000  ...  29.508197  73.770492   \n",
      "2     898.43750  81.079687   0.090245  109.375000  ...  35.294118  69.117647   \n",
      "3    1007.81250  57.914062   0.057465   78.125000  ...  62.295082  83.606557   \n",
      "4     949.21875  69.496875   0.073215   87.890625  ...  48.437500  76.562500   \n",
      "\n",
      "   HRV_MinNN  HRV_MaxNN    HRV_HTI  HRV_TINN  Arousal  Valence  \\\n",
      "0   757.8125  1117.1875  11.166667   171.875     7.71     7.60   \n",
      "1   898.4375  1132.8125  10.166667   125.000     8.10     7.31   \n",
      "2   781.2500  1078.1250  13.600000    78.125     8.58     7.54   \n",
      "3   898.4375  1117.1875  12.200000   125.000     4.94     6.01   \n",
      "4   742.1875  1140.6250  10.666667   156.250     6.96     3.92   \n",
      "\n",
      "          Emotion_Category  Subject  \n",
      "0  HighArousal_HighValence      s01  \n",
      "1  HighArousal_HighValence      s01  \n",
      "2  HighArousal_HighValence      s01  \n",
      "3   LowArousal_HighValence      s01  \n",
      "4   HighArousal_LowValence      s01  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "\n",
    "data_dir = \"data_preprocessed_python/\"\n",
    "all_results = []\n",
    "\n",
    "sampling_rate = 128  # DEAP 数据的采样率\n",
    "\n",
    "# 定义情感分类函数\n",
    "def categorize_emotion(row):\n",
    "    if row['Arousal'] > 5 and row['Valence'] > 5:\n",
    "        return 'HighArousal_HighValence'\n",
    "    elif row['Arousal'] > 5 and row['Valence'] <= 5:\n",
    "        return 'HighArousal_LowValence'\n",
    "    elif row['Arousal'] <= 5 and row['Valence'] > 5:\n",
    "        return 'LowArousal_HighValence'\n",
    "    else:\n",
    "        return 'LowArousal_LowValence'\n",
    "\n",
    "# 初始化一个日志列表，用于记录无法处理的文件和试验\n",
    "error_log = []\n",
    "\n",
    "# 提取每次试验的PRV（HRV代理）特征\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.endswith(\".dat\"):  \n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # 加载每个被试的数据\n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                data = pickle.load(file, encoding='latin1')\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load file {file_name}: {e}\")\n",
    "            error_log.append({\"File\": file_name, \"Trial\": \"ALL\", \"Error\": str(e)})\n",
    "            continue\n",
    "        \n",
    "        # 提取信号和标签\n",
    "        signals = data['data']   # shape: (40 trials, 40 channels, 8064 samples)\n",
    "        labels = data['labels']\n",
    "        \n",
    "        # 提取Plethysmograph信号 (索引39为PPG通道)\n",
    "        ppg_signals = signals[:, 38]\n",
    "        \n",
    "        # 提取每次试验的PRV特征\n",
    "        hrv_features = []\n",
    "        for trial_idx, trial_ppg in enumerate(ppg_signals):\n",
    "            try:\n",
    "                # 检查信号是否有效\n",
    "                if trial_ppg is None or len(trial_ppg) == 0 or np.all(trial_ppg == 0):\n",
    "                    print(f\"Invalid PPG signal in file {file_name}, trial {trial_idx}\")\n",
    "                    error_log.append({\"File\": file_name, \"Trial\": trial_idx, \"Error\": \"Invalid PPG signal\"})\n",
    "                    continue\n",
    "\n",
    "                # 使用ppg_process处理PPG信号\n",
    "                signals_ppg, info_ppg = nk.ppg_process(trial_ppg, sampling_rate=sampling_rate)\n",
    "\n",
    "                # 检查PPG峰是否有效\n",
    "                if 'PPG_Peaks' not in info_ppg or len(info_ppg['PPG_Peaks']) < 2:\n",
    "                    print(f\"No valid PPG peaks detected in file {file_name}, trial {trial_idx}\")\n",
    "                    error_log.append({\"File\": file_name, \"Trial\": trial_idx, \"Error\": \"No valid PPG peaks detected\"})\n",
    "                    continue\n",
    "\n",
    "                # 由于hrv_time函数是针对ECG R-peaks设计，这里我们假装PPG Peaks为R-peaks输入\n",
    "                rpeaks = {\"ECG_R_Peaks\": info_ppg[\"PPG_Peaks\"]}\n",
    "                \n",
    "                # 计算HRV（实际上是PRV）指标\n",
    "                hrv = nk.hrv_time(rpeaks, sampling_rate=sampling_rate)\n",
    "                hrv_features.append(hrv)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing trial {trial_idx} in file {file_name}: {e}\")\n",
    "                error_log.append({\"File\": file_name, \"Trial\": trial_idx, \"Error\": str(e)})\n",
    "                continue\n",
    "\n",
    "        # 转为DataFrame格式\n",
    "        if hrv_features:\n",
    "            hrv_df = pd.concat(hrv_features, ignore_index=True)\n",
    "        else:\n",
    "            print(f\"No valid HRV features extracted for file {file_name}\")\n",
    "            error_log.append({\"File\": file_name, \"Trial\": \"ALL\", \"Error\": \"No valid HRV features\"})\n",
    "            continue\n",
    "                           \n",
    "        # 将情感标签转为DataFrame\n",
    "        labels_df = pd.DataFrame(labels, columns=['Arousal', 'Valence', 'Dominance', 'Liking'])\n",
    "        \n",
    "        # 合并HRV特征和情感标签\n",
    "        result_df = pd.concat([hrv_df, labels_df[[\"Arousal\", \"Valence\"]]], axis=1)\n",
    "        \n",
    "        # 添加情感分类列\n",
    "        result_df['Emotion_Category'] = result_df.apply(categorize_emotion, axis=1)\n",
    "        \n",
    "        # 添加被试编号列（如 s01, s02...）\n",
    "        result_df['Subject'] = file_name.split('.')[0]  # 提取文件名作为被试编号\n",
    "        \n",
    "        # 将每个被试的结果添加到总列表中\n",
    "        all_results.append(result_df)\n",
    "\n",
    "# 合并所有被试的DataFrame\n",
    "if all_results:\n",
    "    final_result_df = pd.concat(all_results, ignore_index=True)\n",
    "else:\n",
    "    final_result_df = pd.DataFrame()\n",
    "\n",
    "# 删除包含 NaN 的列和行\n",
    "final_result_df = final_result_df.dropna(axis=1, how='all')  # 删除所有值为 NaN 的列\n",
    "final_result_df = final_result_df.dropna(axis=0, how='any')  # 删除包含 NaN 的行\n",
    "\n",
    "# 输出无法处理的文件日志\n",
    "error_log_df = pd.DataFrame(error_log)\n",
    "print(\"Error Log:\")\n",
    "print(error_log_df)\n",
    "\n",
    "# 查看最终结果\n",
    "print(final_result_df.head())\n",
    "\n",
    "# 如果需要保存结果\n",
    "final_result_df.to_csv(\"deap_prv_features.csv\", index=False)\n",
    "error_log_df.to_csv(\"deap_prv_error_log.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN</th>\n",
       "      <th>HRV_SDNN</th>\n",
       "      <th>HRV_RMSSD</th>\n",
       "      <th>HRV_SDSD</th>\n",
       "      <th>HRV_CVNN</th>\n",
       "      <th>HRV_CVSD</th>\n",
       "      <th>HRV_MedianNN</th>\n",
       "      <th>HRV_MadNN</th>\n",
       "      <th>HRV_MCVNN</th>\n",
       "      <th>HRV_IQRNN</th>\n",
       "      <th>...</th>\n",
       "      <th>HRV_pNN50</th>\n",
       "      <th>HRV_pNN20</th>\n",
       "      <th>HRV_MinNN</th>\n",
       "      <th>HRV_MaxNN</th>\n",
       "      <th>HRV_HTI</th>\n",
       "      <th>HRV_TINN</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Emotion_Category</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>923.973881</td>\n",
       "      <td>60.447814</td>\n",
       "      <td>78.978529</td>\n",
       "      <td>79.557900</td>\n",
       "      <td>0.065422</td>\n",
       "      <td>0.085477</td>\n",
       "      <td>921.87500</td>\n",
       "      <td>46.331250</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>66.406250</td>\n",
       "      <td>...</td>\n",
       "      <td>37.313433</td>\n",
       "      <td>70.149254</td>\n",
       "      <td>757.8125</td>\n",
       "      <td>1117.1875</td>\n",
       "      <td>11.166667</td>\n",
       "      <td>171.8750</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>HighArousal_HighValence</td>\n",
       "      <td>s01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015.368852</td>\n",
       "      <td>50.650216</td>\n",
       "      <td>53.559802</td>\n",
       "      <td>54.009237</td>\n",
       "      <td>0.049884</td>\n",
       "      <td>0.052749</td>\n",
       "      <td>1015.62500</td>\n",
       "      <td>46.331250</td>\n",
       "      <td>0.045618</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.508197</td>\n",
       "      <td>73.770492</td>\n",
       "      <td>898.4375</td>\n",
       "      <td>1132.8125</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>125.0000</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.31</td>\n",
       "      <td>HighArousal_HighValence</td>\n",
       "      <td>s01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910.615809</td>\n",
       "      <td>72.630760</td>\n",
       "      <td>48.489380</td>\n",
       "      <td>48.851811</td>\n",
       "      <td>0.079760</td>\n",
       "      <td>0.053249</td>\n",
       "      <td>898.43750</td>\n",
       "      <td>81.079687</td>\n",
       "      <td>0.090245</td>\n",
       "      <td>109.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.294118</td>\n",
       "      <td>69.117647</td>\n",
       "      <td>781.2500</td>\n",
       "      <td>1078.1250</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>78.1250</td>\n",
       "      <td>8.58</td>\n",
       "      <td>7.54</td>\n",
       "      <td>HighArousal_HighValence</td>\n",
       "      <td>s01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013.191598</td>\n",
       "      <td>53.589061</td>\n",
       "      <td>76.280305</td>\n",
       "      <td>76.919997</td>\n",
       "      <td>0.052891</td>\n",
       "      <td>0.075287</td>\n",
       "      <td>1007.81250</td>\n",
       "      <td>57.914062</td>\n",
       "      <td>0.057465</td>\n",
       "      <td>78.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.295082</td>\n",
       "      <td>83.606557</td>\n",
       "      <td>898.4375</td>\n",
       "      <td>1117.1875</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>125.0000</td>\n",
       "      <td>4.94</td>\n",
       "      <td>6.01</td>\n",
       "      <td>LowArousal_HighValence</td>\n",
       "      <td>s01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>958.618164</td>\n",
       "      <td>71.503630</td>\n",
       "      <td>95.333233</td>\n",
       "      <td>96.089137</td>\n",
       "      <td>0.074590</td>\n",
       "      <td>0.099449</td>\n",
       "      <td>949.21875</td>\n",
       "      <td>69.496875</td>\n",
       "      <td>0.073215</td>\n",
       "      <td>87.890625</td>\n",
       "      <td>...</td>\n",
       "      <td>48.437500</td>\n",
       "      <td>76.562500</td>\n",
       "      <td>742.1875</td>\n",
       "      <td>1140.6250</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>156.2500</td>\n",
       "      <td>6.96</td>\n",
       "      <td>3.92</td>\n",
       "      <td>HighArousal_LowValence</td>\n",
       "      <td>s01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>723.473837</td>\n",
       "      <td>278.660153</td>\n",
       "      <td>415.687709</td>\n",
       "      <td>418.042013</td>\n",
       "      <td>0.385170</td>\n",
       "      <td>0.574572</td>\n",
       "      <td>664.06250</td>\n",
       "      <td>289.570312</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>435.546875</td>\n",
       "      <td>...</td>\n",
       "      <td>89.534884</td>\n",
       "      <td>94.186047</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1343.7500</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>62.5000</td>\n",
       "      <td>3.91</td>\n",
       "      <td>6.96</td>\n",
       "      <td>LowArousal_HighValence</td>\n",
       "      <td>s32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>719.840116</td>\n",
       "      <td>307.921801</td>\n",
       "      <td>423.836331</td>\n",
       "      <td>426.328604</td>\n",
       "      <td>0.427764</td>\n",
       "      <td>0.588792</td>\n",
       "      <td>671.87500</td>\n",
       "      <td>289.570312</td>\n",
       "      <td>0.430988</td>\n",
       "      <td>408.203125</td>\n",
       "      <td>...</td>\n",
       "      <td>89.534884</td>\n",
       "      <td>95.348837</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1843.7500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>562.5000</td>\n",
       "      <td>2.81</td>\n",
       "      <td>6.13</td>\n",
       "      <td>LowArousal_HighValence</td>\n",
       "      <td>s32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>686.885534</td>\n",
       "      <td>256.077432</td>\n",
       "      <td>347.226057</td>\n",
       "      <td>349.186217</td>\n",
       "      <td>0.372809</td>\n",
       "      <td>0.505508</td>\n",
       "      <td>640.62500</td>\n",
       "      <td>266.404687</td>\n",
       "      <td>0.415851</td>\n",
       "      <td>335.937500</td>\n",
       "      <td>...</td>\n",
       "      <td>88.764045</td>\n",
       "      <td>94.382022</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1460.9375</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>257.8125</td>\n",
       "      <td>3.05</td>\n",
       "      <td>7.01</td>\n",
       "      <td>LowArousal_HighValence</td>\n",
       "      <td>s32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>714.260057</td>\n",
       "      <td>306.562952</td>\n",
       "      <td>397.236920</td>\n",
       "      <td>399.548344</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>0.556152</td>\n",
       "      <td>609.37500</td>\n",
       "      <td>254.821875</td>\n",
       "      <td>0.418169</td>\n",
       "      <td>406.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>90.804598</td>\n",
       "      <td>95.402299</td>\n",
       "      <td>312.5000</td>\n",
       "      <td>1601.5625</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>125.0000</td>\n",
       "      <td>3.99</td>\n",
       "      <td>7.17</td>\n",
       "      <td>LowArousal_HighValence</td>\n",
       "      <td>s32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>766.894531</td>\n",
       "      <td>339.016523</td>\n",
       "      <td>452.103381</td>\n",
       "      <td>454.931018</td>\n",
       "      <td>0.442064</td>\n",
       "      <td>0.589525</td>\n",
       "      <td>714.84375</td>\n",
       "      <td>364.858594</td>\n",
       "      <td>0.510403</td>\n",
       "      <td>511.718750</td>\n",
       "      <td>...</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>304.6875</td>\n",
       "      <td>1796.8750</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>85.9375</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.03</td>\n",
       "      <td>HighArousal_LowValence</td>\n",
       "      <td>s32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HRV_MeanNN    HRV_SDNN   HRV_RMSSD    HRV_SDSD  HRV_CVNN  HRV_CVSD  \\\n",
       "0      923.973881   60.447814   78.978529   79.557900  0.065422  0.085477   \n",
       "1     1015.368852   50.650216   53.559802   54.009237  0.049884  0.052749   \n",
       "2      910.615809   72.630760   48.489380   48.851811  0.079760  0.053249   \n",
       "3     1013.191598   53.589061   76.280305   76.919997  0.052891  0.075287   \n",
       "4      958.618164   71.503630   95.333233   96.089137  0.074590  0.099449   \n",
       "...           ...         ...         ...         ...       ...       ...   \n",
       "1275   723.473837  278.660153  415.687709  418.042013  0.385170  0.574572   \n",
       "1276   719.840116  307.921801  423.836331  426.328604  0.427764  0.588792   \n",
       "1277   686.885534  256.077432  347.226057  349.186217  0.372809  0.505508   \n",
       "1278   714.260057  306.562952  397.236920  399.548344  0.429204  0.556152   \n",
       "1279   766.894531  339.016523  452.103381  454.931018  0.442064  0.589525   \n",
       "\n",
       "      HRV_MedianNN   HRV_MadNN  HRV_MCVNN   HRV_IQRNN  ...  HRV_pNN50  \\\n",
       "0        921.87500   46.331250   0.050258   66.406250  ...  37.313433   \n",
       "1       1015.62500   46.331250   0.045618   62.500000  ...  29.508197   \n",
       "2        898.43750   81.079687   0.090245  109.375000  ...  35.294118   \n",
       "3       1007.81250   57.914062   0.057465   78.125000  ...  62.295082   \n",
       "4        949.21875   69.496875   0.073215   87.890625  ...  48.437500   \n",
       "...            ...         ...        ...         ...  ...        ...   \n",
       "1275     664.06250  289.570312   0.436059  435.546875  ...  89.534884   \n",
       "1276     671.87500  289.570312   0.430988  408.203125  ...  89.534884   \n",
       "1277     640.62500  266.404687   0.415851  335.937500  ...  88.764045   \n",
       "1278     609.37500  254.821875   0.418169  406.250000  ...  90.804598   \n",
       "1279     714.84375  364.858594   0.510403  511.718750  ...  87.500000   \n",
       "\n",
       "      HRV_pNN20  HRV_MinNN  HRV_MaxNN    HRV_HTI  HRV_TINN  Arousal  Valence  \\\n",
       "0     70.149254   757.8125  1117.1875  11.166667  171.8750     7.71     7.60   \n",
       "1     73.770492   898.4375  1132.8125  10.166667  125.0000     8.10     7.31   \n",
       "2     69.117647   781.2500  1078.1250  13.600000   78.1250     8.58     7.54   \n",
       "3     83.606557   898.4375  1117.1875  12.200000  125.0000     4.94     6.01   \n",
       "4     76.562500   742.1875  1140.6250  10.666667  156.2500     6.96     3.92   \n",
       "...         ...        ...        ...        ...       ...      ...      ...   \n",
       "1275  94.186047   304.6875  1343.7500  28.666667   62.5000     3.91     6.96   \n",
       "1276  95.348837   304.6875  1843.7500  21.500000  562.5000     2.81     6.13   \n",
       "1277  94.382022   304.6875  1460.9375  22.250000  257.8125     3.05     7.01   \n",
       "1278  95.402299   312.5000  1601.5625  21.750000  125.0000     3.99     7.17   \n",
       "1279  95.000000   304.6875  1796.8750  20.000000   85.9375     7.15     4.03   \n",
       "\n",
       "             Emotion_Category  Subject  \n",
       "0     HighArousal_HighValence      s01  \n",
       "1     HighArousal_HighValence      s01  \n",
       "2     HighArousal_HighValence      s01  \n",
       "3      LowArousal_HighValence      s01  \n",
       "4      HighArousal_LowValence      s01  \n",
       "...                       ...      ...  \n",
       "1275   LowArousal_HighValence      s32  \n",
       "1276   LowArousal_HighValence      s32  \n",
       "1277   LowArousal_HighValence      s32  \n",
       "1278   LowArousal_HighValence      s32  \n",
       "1279   HighArousal_LowValence      s32  \n",
       "\n",
       "[1280 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据大小: (1280, 23)\n",
      "原始数据大小: (1280, 23)\n",
      "清理后数据大小: (1129, 23)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"deap_prv_features.csv\")\n",
    "\n",
    "print(\"原始数据大小:\", df.shape)\n",
    "\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[float, int]).columns\n",
    "\n",
    "\n",
    "clean_df = df.copy()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = clean_df[col].quantile(0.25)\n",
    "    Q3 = clean_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    clean_df = clean_df[(clean_df[col] >= lower_bound) & (clean_df[col] <= upper_bound)]\n",
    "\n",
    "\n",
    "print(\"原始数据大小:\", df.shape)\n",
    "print(\"清理后数据大小:\", clean_df.shape)\n",
    "clean_df.to_csv(\"deap_prv_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据大小: (1129, 23)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"deap_prv_features.csv\")\n",
    "\n",
    "print(\"原始数据大小:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HRV_MeanNN</th>\n",
       "      <th>HRV_SDNN</th>\n",
       "      <th>HRV_RMSSD</th>\n",
       "      <th>HRV_SDSD</th>\n",
       "      <th>HRV_CVNN</th>\n",
       "      <th>HRV_CVSD</th>\n",
       "      <th>HRV_MedianNN</th>\n",
       "      <th>HRV_MadNN</th>\n",
       "      <th>HRV_MCVNN</th>\n",
       "      <th>HRV_IQRNN</th>\n",
       "      <th>...</th>\n",
       "      <th>HRV_Prc20NN</th>\n",
       "      <th>HRV_Prc80NN</th>\n",
       "      <th>HRV_pNN50</th>\n",
       "      <th>HRV_pNN20</th>\n",
       "      <th>HRV_MinNN</th>\n",
       "      <th>HRV_MaxNN</th>\n",
       "      <th>HRV_HTI</th>\n",
       "      <th>HRV_TINN</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "      <td>1129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>819.388068</td>\n",
       "      <td>138.332082</td>\n",
       "      <td>185.885646</td>\n",
       "      <td>187.074808</td>\n",
       "      <td>0.178290</td>\n",
       "      <td>0.240102</td>\n",
       "      <td>804.535264</td>\n",
       "      <td>123.235380</td>\n",
       "      <td>0.168729</td>\n",
       "      <td>168.589806</td>\n",
       "      <td>...</td>\n",
       "      <td>708.790965</td>\n",
       "      <td>919.782440</td>\n",
       "      <td>46.527753</td>\n",
       "      <td>70.674410</td>\n",
       "      <td>565.814604</td>\n",
       "      <td>1231.219553</td>\n",
       "      <td>13.623153</td>\n",
       "      <td>198.336470</td>\n",
       "      <td>5.264641</td>\n",
       "      <td>5.138175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.508494</td>\n",
       "      <td>102.262578</td>\n",
       "      <td>151.479252</td>\n",
       "      <td>152.391149</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>119.835527</td>\n",
       "      <td>109.526045</td>\n",
       "      <td>0.165553</td>\n",
       "      <td>151.495273</td>\n",
       "      <td>...</td>\n",
       "      <td>171.345192</td>\n",
       "      <td>105.900305</td>\n",
       "      <td>32.961402</td>\n",
       "      <td>21.852244</td>\n",
       "      <td>188.153622</td>\n",
       "      <td>302.244721</td>\n",
       "      <td>7.020999</td>\n",
       "      <td>110.586728</td>\n",
       "      <td>2.131799</td>\n",
       "      <td>2.036932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>608.455882</td>\n",
       "      <td>10.031438</td>\n",
       "      <td>13.941790</td>\n",
       "      <td>14.049766</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>546.875000</td>\n",
       "      <td>11.582812</td>\n",
       "      <td>0.012253</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>393.750000</td>\n",
       "      <td>695.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.121212</td>\n",
       "      <td>304.687500</td>\n",
       "      <td>734.375000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>734.468006</td>\n",
       "      <td>52.191109</td>\n",
       "      <td>45.581100</td>\n",
       "      <td>45.853404</td>\n",
       "      <td>0.061649</td>\n",
       "      <td>0.052553</td>\n",
       "      <td>710.937500</td>\n",
       "      <td>40.539844</td>\n",
       "      <td>0.048346</td>\n",
       "      <td>54.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>507.812500</td>\n",
       "      <td>845.312500</td>\n",
       "      <td>14.492754</td>\n",
       "      <td>53.521127</td>\n",
       "      <td>328.125000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>109.375000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>801.440747</td>\n",
       "      <td>100.593758</td>\n",
       "      <td>142.538353</td>\n",
       "      <td>143.501486</td>\n",
       "      <td>0.116866</td>\n",
       "      <td>0.166618</td>\n",
       "      <td>792.968750</td>\n",
       "      <td>63.705469</td>\n",
       "      <td>0.074440</td>\n",
       "      <td>85.937500</td>\n",
       "      <td>...</td>\n",
       "      <td>739.062500</td>\n",
       "      <td>921.875000</td>\n",
       "      <td>43.076923</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>609.375000</td>\n",
       "      <td>1164.062500</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>5.040000</td>\n",
       "      <td>5.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>901.194853</td>\n",
       "      <td>251.308971</td>\n",
       "      <td>345.148808</td>\n",
       "      <td>347.169505</td>\n",
       "      <td>0.363199</td>\n",
       "      <td>0.497876</td>\n",
       "      <td>906.250000</td>\n",
       "      <td>237.447656</td>\n",
       "      <td>0.360632</td>\n",
       "      <td>324.218750</td>\n",
       "      <td>...</td>\n",
       "      <td>843.750000</td>\n",
       "      <td>984.375000</td>\n",
       "      <td>84.090909</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>703.125000</td>\n",
       "      <td>1429.687500</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>273.437500</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>6.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1161.261792</td>\n",
       "      <td>438.197682</td>\n",
       "      <td>605.714225</td>\n",
       "      <td>610.354616</td>\n",
       "      <td>0.481608</td>\n",
       "      <td>0.692563</td>\n",
       "      <td>1171.875000</td>\n",
       "      <td>451.729688</td>\n",
       "      <td>0.578214</td>\n",
       "      <td>578.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>1117.187500</td>\n",
       "      <td>1203.125000</td>\n",
       "      <td>96.385542</td>\n",
       "      <td>98.958333</td>\n",
       "      <td>1007.812500</td>\n",
       "      <td>2148.437500</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>539.062500</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HRV_MeanNN     HRV_SDNN    HRV_RMSSD     HRV_SDSD     HRV_CVNN  \\\n",
       "count  1129.000000  1129.000000  1129.000000  1129.000000  1129.000000   \n",
       "mean    819.388068   138.332082   185.885646   187.074808     0.178290   \n",
       "std     104.508494   102.262578   151.479252   152.391149     0.143998   \n",
       "min     608.455882    10.031438    13.941790    14.049766     0.010805   \n",
       "25%     734.468006    52.191109    45.581100    45.853404     0.061649   \n",
       "50%     801.440747   100.593758   142.538353   143.501486     0.116866   \n",
       "75%     901.194853   251.308971   345.148808   347.169505     0.363199   \n",
       "max    1161.261792   438.197682   605.714225   610.354616     0.481608   \n",
       "\n",
       "          HRV_CVSD  HRV_MedianNN    HRV_MadNN    HRV_MCVNN    HRV_IQRNN  ...  \\\n",
       "count  1129.000000   1129.000000  1129.000000  1129.000000  1129.000000  ...   \n",
       "mean      0.240102    804.535264   123.235380     0.168729   168.589806  ...   \n",
       "std       0.210777    119.835527   109.526045     0.165553   151.495273  ...   \n",
       "min       0.015017    546.875000    11.582812     0.012253    15.625000  ...   \n",
       "25%       0.052553    710.937500    40.539844     0.048346    54.687500  ...   \n",
       "50%       0.166618    792.968750    63.705469     0.074440    85.937500  ...   \n",
       "75%       0.497876    906.250000   237.447656     0.360632   324.218750  ...   \n",
       "max       0.692563   1171.875000   451.729688     0.578214   578.125000  ...   \n",
       "\n",
       "       HRV_Prc20NN  HRV_Prc80NN    HRV_pNN50    HRV_pNN20    HRV_MinNN  \\\n",
       "count  1129.000000  1129.000000  1129.000000  1129.000000  1129.000000   \n",
       "mean    708.790965   919.782440    46.527753    70.674410   565.814604   \n",
       "std     171.345192   105.900305    32.961402    21.852244   188.153622   \n",
       "min     393.750000   695.312500     0.000000    12.121212   304.687500   \n",
       "25%     507.812500   845.312500    14.492754    53.521127   328.125000   \n",
       "50%     739.062500   921.875000    43.076923    73.333333   609.375000   \n",
       "75%     843.750000   984.375000    84.090909    92.500000   703.125000   \n",
       "max    1117.187500  1203.125000    96.385542    98.958333  1007.812500   \n",
       "\n",
       "         HRV_MaxNN      HRV_HTI     HRV_TINN      Arousal      Valence  \n",
       "count  1129.000000  1129.000000  1129.000000  1129.000000  1129.000000  \n",
       "mean   1231.219553    13.623153   198.336470     5.264641     5.138175  \n",
       "std     302.244721     7.020999   110.586728     2.131799     2.036932  \n",
       "min     734.375000     2.750000     0.000000     1.000000     1.000000  \n",
       "25%    1000.000000     8.300000   109.375000     3.900000     3.740000  \n",
       "50%    1164.062500    11.000000   187.500000     5.040000     5.130000  \n",
       "75%    1429.687500    19.500000   273.437500     7.050000     6.940000  \n",
       "max    2148.437500    36.000000   539.062500     9.000000     9.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"deap_prv_features.csv\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "d:\\python\\lib\\site-packages\\neurokit2\\hrv\\hrv_time.py:161: RuntimeWarning: Mean of empty slice\n",
      "  out[\"MeanNN\"] = np.nanmean(rri)\n",
      "d:\\python\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m ecg_signal \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][:, \u001b[38;5;241m37\u001b[39m]\n\u001b[0;32m      6\u001b[0m rpeaks \u001b[38;5;241m=\u001b[39m nk\u001b[38;5;241m.\u001b[39mecg_findpeaks(trial_ecg, sampling_rate\u001b[38;5;241m=\u001b[39msampling_rate)\n\u001b[1;32m----> 7\u001b[0m hrv \u001b[38;5;241m=\u001b[39m \u001b[43mnk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhrv_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrpeaks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(hrv)\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\neurokit2\\hrv\\hrv_time.py:164\u001b[0m, in \u001b[0;36mhrv_time\u001b[1;34m(peaks, sampling_rate, show, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSDNN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanstd(rri, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m]:\n\u001b[1;32m--> 164\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSDANN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m \u001b[43m_sdann\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSDNNI\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m _sdnni(rri, window\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# Difference-based\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\lib\\site-packages\\neurokit2\\hrv\\hrv_time.py:228\u001b[0m, in \u001b[0;36m_sdann\u001b[1;34m(rri, rri_time, window)\u001b[0m\n\u001b[0;32m    226\u001b[0m     rri_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnancumsum(rri \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Convert timestamps to milliseconds and ensure first timestamp is equal to first interval\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m rri_cumsum \u001b[38;5;241m=\u001b[39m (rri_time \u001b[38;5;241m-\u001b[39m \u001b[43mrri_time\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m+\u001b[39m rri[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m n_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(rri_cumsum[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m window_size))\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_windows \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "with open('data_preprocessed_python/s24.dat', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='latin1')\n",
    "\n",
    "# 数据结构\n",
    "ecg_signal = data['data'][:, 37]\n",
    "rpeaks = nk.ecg_findpeaks(trial_ecg, sampling_rate=sampling_rate)\n",
    "hrv = nk.hrv_time(rpeaks, sampling_rate=sampling_rate)\n",
    "print(hrv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: HRV features calculated successfully.\n",
      "Trial 1: No valid R-peaks detected, skipping.\n",
      "Trial 2: No valid R-peaks detected, skipping.\n",
      "Trial 3: HRV features calculated successfully.\n",
      "Trial 4: No valid R-peaks detected, skipping.\n",
      "Trial 5: No valid R-peaks detected, skipping.\n",
      "Trial 6: No valid R-peaks detected, skipping.\n",
      "Trial 7: HRV features calculated successfully.\n",
      "Trial 8: No valid R-peaks detected, skipping.\n",
      "Trial 9: HRV features calculated successfully.\n",
      "Trial 10: HRV features calculated successfully.\n",
      "Trial 11: HRV features calculated successfully.\n",
      "Trial 12: HRV features calculated successfully.\n",
      "Trial 13: HRV features calculated successfully.\n",
      "Trial 14: HRV features calculated successfully.\n",
      "Trial 15: No valid R-peaks detected, skipping.\n",
      "Trial 16: No valid R-peaks detected, skipping.\n",
      "Trial 17: No valid R-peaks detected, skipping.\n",
      "Trial 18: No valid R-peaks detected, skipping.\n",
      "Trial 19: No valid R-peaks detected, skipping.\n",
      "Trial 20: No valid R-peaks detected, skipping.\n",
      "Trial 21: No valid R-peaks detected, skipping.\n",
      "Trial 22: No valid R-peaks detected, skipping.\n",
      "Trial 23: HRV features calculated successfully.\n",
      "Trial 24: HRV features calculated successfully.\n",
      "Trial 25: No valid R-peaks detected, skipping.\n",
      "Trial 26: No valid R-peaks detected, skipping.\n",
      "Trial 27: No valid R-peaks detected, skipping.\n",
      "Trial 28: HRV features calculated successfully.\n",
      "Trial 29: No valid R-peaks detected, skipping.\n",
      "Trial 30: No valid R-peaks detected, skipping.\n",
      "Trial 31: HRV features calculated successfully.\n",
      "Trial 32: HRV features calculated successfully.\n",
      "Trial 33: HRV features calculated successfully.\n",
      "Trial 34: HRV features calculated successfully.\n",
      "Trial 35: HRV features calculated successfully.\n",
      "Trial 36: HRV features calculated successfully.\n",
      "Trial 37: HRV features calculated successfully.\n",
      "Trial 38: HRV features calculated successfully.\n",
      "Trial 39: HRV features calculated successfully.\n"
     ]
    }
   ],
   "source": [
    "for trial_idx, trial_ecg in enumerate(ecg_signal):\n",
    "    try:\n",
    "        # 检查信号是否有效\n",
    "        if trial_ecg is None or len(trial_ecg) == 0 or np.all(trial_ecg == 0):\n",
    "            print(f\"Trial {trial_idx}: Invalid ECG signal, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 滤波提升信号质量\n",
    "\n",
    "        # 检测R波峰\n",
    "        rpeaks = nk.ecg_findpeaks(trial_ecg, sampling_rate=sampling_rate)\n",
    "        if 'ECG_R_Peaks' not in rpeaks or len(rpeaks['ECG_R_Peaks']) < 2:\n",
    "            print(f\"Trial {trial_idx}: No valid R-peaks detected, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 计算HRV指标\n",
    "        hrv = nk.hrv_time(rpeaks, sampling_rate=sampling_rate)\n",
    "        print(f\"Trial {trial_idx}: HRV features calculated successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial_idx}: Error occurred - {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing s01.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s02.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s03.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s04.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s05.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s06.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s07.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s08.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s09.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s10.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s11.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s12.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s13.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s14.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s15.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s16.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s17.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s18.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s19.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s20.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s21.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s22.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s23.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s24.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s25.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s26.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s27.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s28.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s29.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s30.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s31.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n",
      "Processing s32.dat\n",
      "Data keys: ['labels', 'data']\n",
      "Data shape: (40, 40, 8064), Labels shape: (40, 4)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"data_preprocessed_python/\"\n",
    "\n",
    "# 检查文件内容是否一致\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.endswith(\".dat\"):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                data = pickle.load(file, encoding='latin1')\n",
    "            \n",
    "            # 检查文件结构\n",
    "            print(f\"Processing {file_name}\")\n",
    "            print(f\"Data keys: {list(data.keys())}\")\n",
    "            print(f\"Data shape: {data['data'].shape}, Labels shape: {data['labels'].shape}\")\n",
    "        \n",
    "        except Exception as e:                      \n",
    "            print(f\"Error reading file {file_name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
